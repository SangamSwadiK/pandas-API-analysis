{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing of Jupyter Notebooks from Github\n",
    "\n",
    "Starting from a set of scripts that were converted from Jupyter notebooks, we perform Token search, then post-process the data for further analysis.\n",
    "\n",
    "Our end result should be a DataFrame where each row corresponds to a script, and there is a column for each Token, indicating the number of times a token appears in a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 10:37:07,977\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '127.0.0.1',\n",
       " 'raylet_ip_address': '127.0.0.1',\n",
       " 'redis_address': '127.0.0.1:17991',\n",
       " 'object_store_address': '/tmp/ray/session_2022-02-09_10-37-04_107820_61570/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-02-09_10-37-04_107820_61570/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8266',\n",
       " 'session_dir': '/tmp/ray/session_2022-02-09_10-37-04_107820_61570',\n",
       " 'metrics_export_port': 65533,\n",
       " 'node_id': '135e2e2adac2c7cafd111186fda3b116a099ea6196c087b24bf4e532'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "from inspect import isclass, isfunction, ismodule\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import modin.pandas as mpd\n",
    "import pandas as pd\n",
    "import ray\n",
    "import regex\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the set of search tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compile a list of pandas functions.\n",
    "\"\"\"\n",
    "\n",
    "# Get all the possible functions from these pandas classes and their subclasses.\n",
    "allowed_classes = [\n",
    "    pd,\n",
    "    pd.DataFrame,\n",
    "    pd.Series,\n",
    "    pd.io,\n",
    "    pd.core,\n",
    "    pd.Index,\n",
    "    pd.RangeIndex,\n",
    "    pd.CategoricalIndex,\n",
    "    pd.IntervalIndex,\n",
    "    pd.MultiIndex,\n",
    "    pd.IndexSlice,\n",
    "    pd.DatetimeIndex,\n",
    "    pd.TimedeltaIndex,\n",
    "    pd.PeriodIndex,\n",
    "    pd.Timestamp,\n",
    "    pd.Timedelta,\n",
    "    pd.DatetimeTZDtype,\n",
    "    pd.Period,\n",
    "    pd.Interval,\n",
    "    pd.Categorical,\n",
    "    pd.arrays,\n",
    "    pd.tseries,\n",
    "    pd.plotting,\n",
    "    pd.api,\n",
    "]\n",
    "classes = [(pd, \"pandas\")]\n",
    "\n",
    "functions = set()\n",
    "indexers = [\"iloc\", \"iat\", \"ix\", \"loc\", \"at\"]\n",
    "\n",
    "while classes:\n",
    "    obj, prefix = classes.pop()\n",
    "    for token, t in vars(obj).items():\n",
    "        # We do not consider unders, duners, or properties.\n",
    "        if token[0] == \"_\" or token[:2] == \"__\":\n",
    "            continue\n",
    "        elif isfunction(t):\n",
    "            if prefix.split(\".\")[-1] == \"io\":\n",
    "                print(type(obj), prefix)\n",
    "            functions.add(f\"{prefix}.{token}\")\n",
    "        elif isclass(t) or ismodule(t):\n",
    "            if (\n",
    "                prefix.count(\".\") > 5  # Prune search tree depth.\n",
    "                or t not in allowed_classes\n",
    "                or prefix.split(\".\")[-1] == token\n",
    "            ):\n",
    "                continue\n",
    "            classes.append((t, f\"{prefix}.{token}\"))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "# Compute the set of unique function names.\n",
    "function_set = set([f.split(\".\")[-1] for f in functions])\n",
    "len(function_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To reduce false positives, we block the following prefixes:\n",
    "    - numpy and matplotlib prefixes\n",
    "    - ' and \" for string functions, like format\n",
    "    - ] and } for list and dict types\n",
    "    \n",
    "Then we convert function names to regex tokens.\n",
    "\"\"\"\n",
    "\n",
    "blocked_prefixes = \"(?<!numpy|np|plt|matplotlib|\\\"|'|]|})\"\n",
    "function_token_set = {f\"{blocked_prefixes}\\.{f}\\(\" for f in function_set}\n",
    "indexer_token_set = {f\"\\.{indexer}\\[\" for indexer in indexers}\n",
    "pandas_token_set = {\"pd\", \"pandas\"}\n",
    "search_tokens_set = function_token_set | indexer_token_set | pandas_token_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search each script file for search tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'list'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250042</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250043</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250044</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250045</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250046</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250047 rows x 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              script_path\n",
       "0       ../../pandas-api-analysis-private/data/big_dat...\n",
       "1       ../../pandas-api-analysis-private/data/big_dat...\n",
       "2       ../../pandas-api-analysis-private/data/big_dat...\n",
       "3       ../../pandas-api-analysis-private/data/big_dat...\n",
       "4       ../../pandas-api-analysis-private/data/big_dat...\n",
       "...                                                   ...\n",
       "250042  ../../pandas-api-analysis-private/data/big_dat...\n",
       "250043  ../../pandas-api-analysis-private/data/big_dat...\n",
       "250044  ../../pandas-api-analysis-private/data/big_dat...\n",
       "250045  ../../pandas-api-analysis-private/data/big_dat...\n",
       "250046  ../../pandas-api-analysis-private/data/big_dat...\n",
       "\n",
       "[250047 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of the python scripts.\n",
    "\n",
    "python_scripts = []\n",
    "scripts_dir = \"../../pandas-api-analysis-private/data/big_dataset/converted_scripts/\"\n",
    "\n",
    "for f in os.listdir(scripts_dir):\n",
    "    if not f.startswith(\".\") and not f.endswith(\"csv\"):\n",
    "        python_scripts.append(os.path.join(scripts_dir, f))\n",
    "\n",
    "python_scripts_df = mpd.DataFrame(python_scripts, columns=[\"script_path\"])\n",
    "python_scripts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the helper we apply to the DataFrame to parse a script for its tokens.\n",
    "\n",
    "\n",
    "def parse_file_tokens(file_path, search_tokens):\n",
    "    \"\"\"Parse the file and search for the desired regex expressions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path: str\n",
    "        File path to search for.\n",
    "    search_tokens: iterable\n",
    "        Regex expressions as an iterable.\n",
    "    \"\"\"\n",
    "    with open(file_path) as f:\n",
    "        contents = f.read()\n",
    "    search_tokens = regex.compile(\"|\".join(search_tokens))\n",
    "    return Counter(regex.findall(search_tokens, contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: User-defined function verification is still under development in Modin. The function provided is not verified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                   {'pandas': 2, 'pd': 2, '.read_csv(': 1}\n",
       "1         {'pandas': 3, 'pd': 1, '.append(': 2, '.min(':...\n",
       "2         {'pandas': 2, 'pd': 4, '.stack(': 3, '.unstack...\n",
       "3         {'pandas': 2, 'pd': 13, '.read_csv(': 2, '.inf...\n",
       "4         {'pandas': 1, 'pd': 4, '.join(': 1, '.iloc[': ...\n",
       "                                ...                        \n",
       "250042    {'pandas': 1, 'pd': 10, '.read_csv(': 2, '.dro...\n",
       "250043                  {'pandas': 1, 'pd': 5, '.mean(': 3}\n",
       "250044                         {'pandas': 1, '.fillna(': 1}\n",
       "250045                {'pd': 2, 'pandas': 1, '.append(': 2}\n",
       "250046    {'pandas': 2, 'pd': 23, '.read_csv(': 2, '.tol...\n",
       "Length: 250047, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warning: this step will take > 10 min.\n",
    "# Use parse script to get a Counter of the tokens in each script.\n",
    "\n",
    "script_tokens_ser = python_scripts_df.apply(\n",
    "    lambda row: parse_file_tokens(row[\"script_path\"], search_tokens_set),\n",
    "    axis=\"columns\",\n",
    ")\n",
    "\n",
    "script_tokens_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_path</th>\n",
       "      <th>script_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "      <td>{'pandas': 2, 'pd': 2, '.read_csv(': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "      <td>{'pandas': 3, 'pd': 1, '.append(': 2, '.min(':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "      <td>{'pandas': 2, 'pd': 4, '.stack(': 3, '.unstack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "      <td>{'pandas': 2, 'pd': 13, '.read_csv(': 2, '.inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "      <td>{'pandas': 1, 'pd': 4, '.join(': 1, '.iloc[': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250042</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "      <td>{'pandas': 1, 'pd': 10, '.read_csv(': 2, '.dro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250043</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "      <td>{'pandas': 1, 'pd': 5, '.mean(': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250044</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "      <td>{'pandas': 1, '.fillna(': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250045</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "      <td>{'pd': 2, 'pandas': 1, '.append(': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250046</th>\n",
       "      <td>../../pandas-api-analysis-private/data/big_dat...</td>\n",
       "      <td>{'pandas': 2, 'pd': 23, '.read_csv(': 2, '.tol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250047 rows x 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              script_path  \\\n",
       "0       ../../pandas-api-analysis-private/data/big_dat...   \n",
       "1       ../../pandas-api-analysis-private/data/big_dat...   \n",
       "2       ../../pandas-api-analysis-private/data/big_dat...   \n",
       "3       ../../pandas-api-analysis-private/data/big_dat...   \n",
       "4       ../../pandas-api-analysis-private/data/big_dat...   \n",
       "...                                                   ...   \n",
       "250042  ../../pandas-api-analysis-private/data/big_dat...   \n",
       "250043  ../../pandas-api-analysis-private/data/big_dat...   \n",
       "250044  ../../pandas-api-analysis-private/data/big_dat...   \n",
       "250045  ../../pandas-api-analysis-private/data/big_dat...   \n",
       "250046  ../../pandas-api-analysis-private/data/big_dat...   \n",
       "\n",
       "                                            script_tokens  \n",
       "0                 {'pandas': 2, 'pd': 2, '.read_csv(': 1}  \n",
       "1       {'pandas': 3, 'pd': 1, '.append(': 2, '.min(':...  \n",
       "2       {'pandas': 2, 'pd': 4, '.stack(': 3, '.unstack...  \n",
       "3       {'pandas': 2, 'pd': 13, '.read_csv(': 2, '.inf...  \n",
       "4       {'pandas': 1, 'pd': 4, '.join(': 1, '.iloc[': ...  \n",
       "...                                                   ...  \n",
       "250042  {'pandas': 1, 'pd': 10, '.read_csv(': 2, '.dro...  \n",
       "250043                {'pandas': 1, 'pd': 5, '.mean(': 3}  \n",
       "250044                       {'pandas': 1, '.fillna(': 1}  \n",
       "250045              {'pd': 2, 'pandas': 1, '.append(': 2}  \n",
       "250046  {'pandas': 2, 'pd': 23, '.read_csv(': 2, '.tol...  \n",
       "\n",
       "[250047 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the scripts DataFrame and the new series.\n",
    "python_script_tokens_df = mpd.concat([python_scripts_df, script_tokens_ser], axis=1)\n",
    "python_script_tokens_df.rename({0: \"script_tokens\"}, axis=1, inplace=True)\n",
    "python_script_tokens_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the token counters to DF columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the display names of all search tokens.\n",
    "function_token_dnames = {f\".{f}(\" for f in function_set}\n",
    "indexer_token_dnames = {f\".{indexer}[\" for indexer in indexers}\n",
    "pandas_token_dnames = {\"pd\", \"pandas\"}\n",
    "all_tokens = function_token_dnames | indexer_token_dnames | pandas_token_dnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper to get the count for a token.\n",
    "\n",
    "\n",
    "def get_token(row: str, token):\n",
    "    try:\n",
    "        return row[token]\n",
    "    except Exception:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: this step will take > 10 min.\n",
    "\n",
    "for token in all_tokens:\n",
    "    python_script_tokens_df[token] = python_script_tokens_df[\"script_tokens\"].apply(\n",
    "        lambda row: get_token(row, token)\n",
    "    )\n",
    "python_script_tokens_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm all column names are unique\n",
    "assert all(\n",
    "    [count == 1 for f, count in Counter(python_script_tokens_df.columns).items()]\n",
    "), \"Column names should be unique.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove irrevelant tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional tokens to exclude.\n",
    "exclude = set([\"pandas\", \"pd\"])\n",
    "exclude = exclude.intersection(set(python_script_tokens_df.columns))\n",
    "print(len(exclude))\n",
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove these tokens from the df.\n",
    "python_script_tokens_df.drop(labels=exclude, inplace=True, axis=1)\n",
    "python_script_tokens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with no tokens.\n",
    "token_count = python_script_tokens_df.iloc[:, 2:].sum(axis=1)\n",
    "token_count = token_count[token_count == 0].index\n",
    "token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_script_tokens_df = python_script_tokens_df.drop(labels=token_count, axis=0)\n",
    "python_script_tokens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Save to csv.\n",
    "python_script_tokens_df.to_csv(\"filtered_token_breakdown.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
